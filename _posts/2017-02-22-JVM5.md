---
date: 2017/2/22 星期三  9:54:22+0800
layout: post
title: 深入理解Java虚拟机(5)-调优案例分析
thread: 164
categories: 读书笔记
tags:  深入理解Java虚拟机
---

本文分享了几个比较有代表性的实际案例。


## 1.高性能硬件上的程序部署策略

### 案例

一个15万PV/天左右的文档类型网站最近更换了硬件系统，新的硬件为4个CPU、16GB物理内存，操作系统为64位CentOS 5.4，Resin作为Web服务器。服务器上没有其他应用。为了尽量利用硬件资源选用了64位的JDK 1.5，并通过-Xmx和-Xms参数将Java堆固定在12GB。使用一段时间后发现使用效果并不理想，网站经常不定期出现长时间失去响应的情况。

### 原因

监控服务器运行状况后发现网站失去响应是由GC停顿导致的，虚拟机运行的Server模式，默认使用吞吐量优先收集器，回收12GB的堆，一次Full GC的停顿时间高达14秒。并且由于程序设计的关系，访问文档时要把文档从磁盘提取到内存中，导致内存中出现很多由文档序列化产生的大对象，这些大对象很多都进入了老年代，没有在Minor GC中清理掉。这种情况下即使有12GB的堆，内存也很快被消耗殆尽，由此导致每隔十几分钟就出现十几秒的停顿。

### 分析

高性能硬件上部署程序，目前主要有两种方式：

1. 通过64位JDK来使用大内存。
2. 使用若干个32位虚拟机建立逻辑集群来利用硬件资源。

此案例采用了第一种部署方式。对于用户交互性强、对停顿时间敏感的系统，可以给Java虚拟机分配超大堆的前提是有把握把应用程序Full GC频率控制得足够低，至少要低到不会影响用户使用。

如果使用64位JDK来管理大内存，还需要考虑下面可能面临的问题：内存回收导致的长时间停顿。

相同的程序在64位JDK消耗的内存一般比32位JDK大，这是由于指针膨胀，以及数据类型对齐补白等因素导致的。

所以现阶段不少管理员会选择第二部署方式，具体做法是在一台物理机器上启动多个应用服务器进程，每个服务器进程分配不同端口，然后前端搭建一个负载均衡器，以反向代理的方式来分配访问请求。

当然，这第二种方案也有缺点，如果使用这种方式来部署程序，可能会遇到下面一些问题：

- 尽量避免节点竞争全局的资源。最典型的就是磁盘竞争，各个节点如果同时访问某个磁盘文件的话，很容易导致IO异常。
- 很难最高效率地利用某些资源池。譬如连接池，一般都是在各个节点建立自己独立的连接池，这样有可能导致一些节点池满了而另外一些节点仍有较多空余。
- 各个节点仍然不可避免地受到32位的内存限制。
- 大量使用本地缓存的应用，在逻辑集群中会造成较大的内存浪费，因为每个逻辑节点上都有一份缓存，这时候可以考虑把本地缓存改为**集中式缓存**。

### 解决方案

部署方案调整为建立5个32位JDK的逻辑集群，每个进程按2GB内存计算(其中堆固定为1.5GB)，占用了10GB内存。另外建立一个Apache服务作为前端均衡代理访问门户。考虑到用户对响应速度比较关心，并且文档服务的主要压力集中在磁盘和内存访问，CPU资源敏感度较低，因此改为CMS收集器进行垃圾回收。


## 2.堆外内存导致的溢出错误

### 案例

一个学校的小型项目：基于B/S的电子考试系统，为了实现客户端能实时地从服务器端接收考试数据，系统使用了逆向AJAX技术，选用CometD 1.1.1作为服务端推送框架，服务器是Jetty 7.1.4，硬件为一台普通PC机，Core i5 CPU，4GB内存，运行32位Windows操作系统。

### 现象

测试期间发现服务端不定时抛出内存溢出异常，服务器不一定每次都会出现异常，网站管理员尝试过把堆开到最大（32位系统最多到1.6GB就基本无法再加大了），基本没有效果，抛出内存溢出异常好像还更加频繁了。加入`-XX:+HeapDumpOnOutOfMemoryError` 居然也没有任何反应，抛出内存溢出异常时什么文件都没有产生。使用jstat命令查看，发现GC并不频繁，Eden区、Survivor区、老年代以及永久代内存全部都表示**情绪稳定，压力不大**，但就是照样不停地抛出内存溢出异常。最后，在内存溢出后从系统日志中找到异常堆栈。如下所示：

```
[org.eclipse.jetty.util.log]handle failed java.lang.OutOfMemoryError：null
at sun.misc.Unsafe.allocateMemory（Native Method）
at java.nio.DirectByteBuffer.＜init＞（DirectByteBuffer.java：99）
at java.nio.ByteBuffer.allocateDirect（ByteBuffer.java：288）
at org.eclipse.jetty.io.nio.DirectNIOBuffer.＜init＞
……
```

### 分析

看到异常堆栈信息就清楚这个抛出内存溢出异常是怎么回事了。原因是操作系统对每个进程能管理的内存是有限制的，这台服务器使用的32位Windows平台的限制是2GB，其中划了1.6GB给Java堆，而Direct Memory内存并不算入1.6GB的堆之内，因此它最大也只能在剩余的0.4GB空间中分出一部分。

在此应用中导致溢出的关键是：垃圾收集进行时，虚拟机虽然会对Direct Memory进行回收，但是Direct Memory却不能像新生代、老年代那样，发现空间不足了就通知收集器进行垃圾回收，它只能等待老年代满了后Full GC，然后“顺便地”帮它清理掉内存的废弃对象。否则它只能一直等到抛出内存溢出异常时，先catch掉，再在catch块里面大喊一声:System.gc()。要是虚拟机还是不听（譬如打开了-xx:DisableExplicitGC开关），那就只能眼睁睁地看着堆中还有许多空闲内存，自己却不得不抛出内存溢出异常了。而本案例中，正好有大量的NIO操作需要使用到Direct Memory内存。

除了Java堆和永久代之外，下面这些区域还会占用较多的内存，这里所有的内存总和受到操作系统进程最大内存的限制。

- Direct Memory:`-XX:MaxDirectMemorySize`调整大小，内存不足时抛出OutOfMemoryError或者OutOfMemoryError:Direct buffer memory。
- 线程堆栈:可通过`-Xss`调整大小，内存不足时抛出StackOverflowError（无法分配新的栈帧）或者OutOfMemoryError：unable to create new native thread(无法建立新的线程)。
- Socket缓存区:每个Socket连接都Receive和Send两个缓存区，分别占大约37KB和25KB内存，连接多的话这块内存占用也比较可观。如果无法分配，则可能会抛出IOException：Too many open files异常。
JNI代码：如果代码中使用JNI调用本地库，那本地库使用的内存也不在堆中。
虚拟机和GC:虚拟机、GC的代码执行也要消耗一定的内存。

## 3.外部命令导致系统缓慢

### 案例

一个数字校园的应用系统，在做大并发压力测试的时候，发现请求响应时间比较慢，通过操作系统的mpstat工个发现CPU使用率很高，并且系统占用绝大多数的CPU资源的程序并不是应用系统本身。这是个不正常的现象，通常情况下用户应用的CPU占用率应该占主要地位，才能说明系统是正常工作的。

### 现象

通过运行Solaris 10的Dtrace脚本发现最消耗CPU资源的是`fork`系统调用。

### 分析

fork系统调用是Linux用来产生新**进程**的，在Java虚拟机中，用户编写的Java代码最多只有线程的概念，不应当有进程产生。

最终通过系统的开发人员找到了答案：每个用户的处理都需要执行一个外部shell脚本来获得系统的一些信息。执行这个shell脚本是通过Java的Runtime。getRuntime().exec()方法来调用的。这种调用方式可以达到目的，但是它在Java虚拟机中是非常消耗资源的操作，即使外部命令本身很快执行完毕，频繁调用时创建进行的开销也非常可观。

Java虚拟机执行这个命令的过程是：首先克隆一个和当前虚拟机拥有一样环境变量的进程，再用这个新的进程去执行外部命令，最后再退出这个进程。如果频繁执行这个操作，系统的消耗会很大，不仅是CPU，内存负担也很重。

### 解决方案

去掉这个Shell脚本执行的语句，改为使用Java API去获取这些信息后，系统很快恢复正常。

## 4.不恰当数据结构导致内存占用过大

### 案例

有一个RPC服务器，使用64位虚拟机，内存配置为-Xms4g -Xmx8g -Xmn1g，使用ParNew+CMS的收集器组合。平时对外服务的Minor GC时间约在30毫秒以内，突然地全可以接受。但业务上需要每10分钟加载一个约80MB的数据文件到内存进行数据分析，这些数据会在内存中形成超过100万个HashMap<Long, Long>Entry，在这段时间里面Minor GC就会造成超过500毫秒的停顿，对于这个停顿时间就接受不了了。

### 原因

观察这个案例，发现平时的Minor GC时间很短，原因是新生代的绝大部分对象者是可清除的，在Minor GC之后Eden和Survivor基本上处于完全空闲的状态，而在分析数据文件期间，800MB的Eden空间很快被填满从而引发GC，但Minor GC之后，新生代中绝大部分对象依然是存活的。由于ParNew收集器使用的是复制算法，这个算法的高效是建立在大部分对象都**朝生夕灭**的特性上的，如果存活对象过多，把这些对象复制到Survivor并维持这些对象引用的正确就成为一个沉重的负担，因此导致GC暂停时间明显变长。

### 解决方案

如果不修改程序，仅从GC调估的角度去解决这个问题，可以考虑将Survivor空间去掉（加入参数-XX:SurvivorRatio=65536
、-XX:MaxTenuringThreshold=0或者-XX:+AlwaysTenure），让新生代中存活的对象在第一次Minor GC后立即进入老年代，等到Major GC的时候再清理它们。这种措施可以治标，但也很大副作用，治本的方案需要修改程序，因为这里的问题产生的根本原因是用HashMap<Long, Long>结构来存储数据文件空间效率太低。

### 空间效率分析

在HashMap<Long, Long>结构中，只有Key和Value所存放的两个长整型数据是有效数据，共16B(2×8)。这两个长整型数据包装成java.lang.Long对象之后，就分别具有8B的MarkWord、8B的Klass指针，在加8B存储数据的long值。在这两个Long对象组成Map.Entry之后，又多了16B的对象头，然后一个8B的next字段和4B的int型的hash字段，为了对齐，还必须添加4B的空白填充，最后还有HashMap中对这个Entry的8B的引用，这样增加两个长整型数字，实际耗费的内存为88B，空间效率为18%，实在太低了。