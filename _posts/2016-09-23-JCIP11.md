---
date: 2016/9/23 星期五  12:09:27+0800
layout: post
title: JCIP11-性能与可伸缩性
thread: 164
categories: 读书笔记
tags:  读书笔记
---

线程的最主要目的是提高程序的运行性能。包括提高系统的资源利用率，以及提高系统的响应性。本章将介绍各种分析、监测以及提升并发程序性能的技术。然而，许多提升性能的技术同样会增加复杂性，因此也就增加了在安全性和活跃性上发生失败的风险。虽然我们希望获得更好的性能，但始终要把安全性放在第一位。

## 1. 对性能的思考

使用多线程的目标是提升整体性能，但与单线程的方法相比，使用多个线程总会引入一些额外的性能开销。如果过度地使用线程，那么这些开销甚至会超过由于提高吞吐量、响应性或者计算能力所带来的性能提升。另一方面，一个并发设计很糟糕的应用程序，其性能甚至比实现相同功能的串行程序的性能还要差。

要想通过并发来获得更好的性能，需要努力做好两件事情：

- 更有效地利用现有处理资源
- 在出现新的处理资源时使程序尽可能地利用这些新资源

### 1.1 性能与可伸缩性[^1]

衡量应用程序性能的指标：服务时间、延迟时间、吞吐率、效率、可伸缩性以及容量等。
在并发应用程序中针对可伸缩性进行设计和调优时所采用的方法与传统的性能调优方法截然不同。当进行性能调优时，其目的通常是用更小的代价完成相同的工作。在进行可伸缩性调优时，其目的是设法将问题的计算并行化，从而能利用更多的计算资源来完成更多的工作。

### 1.2 评估各种性能权衡因素

避免不成熟的优化。首先使程序正确，然后再提高运行速度——如果它还运行得不够快。

当时行决策时，有时候会通过增加某种形式的成本来降低另一种形式的开销，也会通过增加开销来换取安全性。很多性能优化措施通常是以牺牲或读性或可维护性为代价。有时候，优化措施会破坏面向对象的设计原则。
在大多数性能决策中都包含有多个变量，并且非常依赖于运行环境。在使某个方案比其他方案“更快”之前，首先问自己一些问题：
- “更快”的含义是什么？
- 该方法是在什么条件下运行得更快？在低负载还是高负载的情况下？大数据集还是小数据集？能否通过测试结果来验证你的答案？
- 在其他不同条件的环境中能否使用这里的代码？
- 在实现这种性能提升时需要付出哪些隐含的代价，例如增加开发风险或维护开销？这种权衡是否合适？

在进行任何与性能相关的决策时，都应该考虑这些问题。

## 2. Amdahl定律

有些问题中， 如果可用资源越多，那么问题的解决速度就越快。而有些任务本质上是串行的。
Amdahl定律描述的是：在增加计算资源的情况下，程序在理论上能够实现最高加速比，这个值取决于程序中可并行组件与串行组件所占的比重。假定F是必须被串行执行的部分，那么根据Amdahl定律， 在包含N个处理器的机器中，最高的加速比为：

![Alt text](/assets/jcip/speedup.png)

### 2.1 在各种框架中隐藏的串行部分

要想知道串行部分是如何隐藏在应用程序的架构中，可以比较当增加线程时吞吐量的变化，并根据观察到的可伸缩性变化来推断串行部分中的差异。

## 3. 线程引入的开销

在多个线程的调度和协调过程中都需要一定的性能开销：对于为了提升性能而引入的线程来说，并行带来的性能提升必须超过并发导致的开销。

### 3.1 上下文切换

切换上下文需要一定的开销，在这个过程中将保存当前运行线程的执行上下文，并将新调度进来的线程的执行上下文切换为当前上下文。

### 3.2 内存同步

同步操作的性能开销包括多个方面。在synchronized 和 volatile提供的可见性保证中可能会使用一些特殊指令，即内存栅栏（Memory Barrier）。内存栅栏可能会对性能带来间接的影响，因为他们将抑制一些编译器优化操作。在内存栅栏中，大多数操作都是不能被重排序的。
在评估同步操作带来的性能影响时，区分有竞争的同步和无竞争的同步非常重要。synchronized机制针对无竞争的同步进行了优化（volatile通常是非竞争的）。虽然无竞争同步的开销不为零，但它对应用程序整体性能的影响微乎其微。
现代的JVM能通过优化来去掉一些不会发生竞争的锁，从而减少不必要的同步开销。如果一个锁对象只能由当前线程访问，那么JVM就可以通过优化来去掉这个锁获取操作，因为另一个线程无法与当前线程在这个锁上发生同步。
不要过度担心非竞争同步带来的开销。这个基本的机制已经非常快了，并且JVM还能进行额外的优化进一步降低或消除开销。因此，我们应该将优化重点放在那些发生锁竞争的地方。

### 3.3 阻塞

非竞争的同步可以完全在JVM中进行处理，而竞争的同步可能需要操作系统的介入，从而增加开销。
当线程被阻塞时，需要被挂起，在这个过程中将包含两次额外的上下文切换，以及所有必要的操作系统操作和缓存操作：被阻塞的线程在其执行时间还未用完之前就被交换出去，而在随后当要获取的锁或者其他资源可用时，又再次被切换回来。

## 4. 减少锁的竞争

减少锁的竞争能够提高性能和可伸缩性。有三种方式可以降低锁的竞争程度：

- 减少锁的持有时间
- 降低锁的请求频率
- 使用带有协调机制的独占锁，这些机制允许更高的并发性。 

### 4.1 缩小锁的范围（“快进快出”）

降低发生竞争可能性的一种有效方式就是尽可能缩短锁的持有时间。例如，可以将一些与锁无关的代码移出同步代码块，尤其是那些开销较大的操作，以及可能被阻塞的操作，例如I/O操作。通过缩小锁的作用范围，能极大地减少在持有锁时需要执行的指令数量。根据Amdahl定律，这样消除了限制可伸缩性的一个因素，因为串行代码的问题减少了。

### 4.2 减小锁的粒度

另一种减少锁的持有时间的方式是降低线程请求锁的频率（从而减少发生竞争的可能性）。这可以通过 **锁分解** 和 **锁分段** 等技术来实现，在这些技术中将采用多个相互独立的锁来保护独立的状态变量，从而改变这些变量在之前由单个锁来保护的情况。这些技术能减小锁操作的粒度，并能实现更高的可伸缩性，然而，使用的锁越多，那么发生死锁的风险也就越高。

如果在锁上存在适中而不是激烈的竞争时，通过将一个锁分解为两个锁，能最大限度地提升性能。如果对竞争并不激烈的锁进行分解，那么在性能和吞吐量等方面带来的提升将非常有限，但是也会提高性能随着竞争提高而下降的拐点值。对竞争适中的锁进行分解时，实际上是把这些锁转变为非竞争的锁，从而有效地提高性能和可伸缩性。

### 4.3 锁分段

把一个竞争激烈的锁分解为两个锁时，这两具锁可能都存在激烈的竞争。虽然采用两个线程并发执行能提高一部分可伸缩性，但在一个拥有多个处理器的系统中，仍然无法给可伸缩性带来极大的提高。
在某些情况下，可以将锁分解技术进一步扩展为结一组独立对象上的锁进行分解，这种情况被称为锁分段。例如：ConcurrentHashMap的实现中使用了一个包含16个锁的数组，每个锁保护所有散列桶的1/16，其中第N个散列桶由第（N mod 16）个锁来保护。假设散列函数具有合理的分布性，并且关键字能够实现均匀分布，那么这大约能把对于锁的请求减少到原来的1/16。

### 4.4 避免热点域

当实现HashMap时，你需要考虑如何在size方法中计算Map中的元素数量。最简单的方法就是，在每次调用时都统计一次元素的数量。一种常见的优化措施是，在插入和移除元素时更新一个计数器。

在单线程或者采用完全同步的实现中，使用一个独立的计数能很好地提高类似size和isEmpty这些方法的执行速度。即使使用锁分段技术来实现散列链，那么在对计数器的访问进行同步时，也会重新导致在使用独占锁时存在的可伸缩性问题。一个看似性能优化的措施——缓存size操作的结果，已经变成了一个可伸缩性问题。在这种情况下，计数器也被称为热点域，因为每个导致元素数量变化的操作都需要访问它。

为了避免这个问题，ConcurrentHashMap中的size将对每个分段进行枚举并将每个分段中的元素数量相加，而不是维护一个全局计数。为了避免枚举每个元素，ConcurrentHashMap为每个分段都维护了一个独立的计数，并通过每个分段的锁来维护这个值。

### 4.5 一些替代独占锁的方法

第三种降低竞争锁的影响的技术就是放弃使用独占锁，从而有助于使用一种友好并发的方式来管理共享状态。例如,使用并发容器、读-写锁、不可变对象以及原子变量。

### 4.6 监测CPU的利用率

当测试可伸缩性时，通常要确保处理器得到充分利用。如果所有CPU的利用率并不均匀，那么你的首要目标就是进一步找出程序中的并行性。不均匀的利用率表明大多数的计算都是由一小组线程完成的，并且应用程序没有利用其他的处理器。
如果CPU没有得到充分利用，那么需要找出其中的原因。通常有以下几种原因：

- 负载不充足
- I/O密集
- 外部限制
- 锁竞争

如果应用程序正在使CPU保持忙碌状态，那么可以使用监视工具来判断是否能通过增加额外的CPU来提升程序的性能。如果一个程序只有4个线程，那么可以充分利用一个4路系统的计算能力，但当移植到8路系统上时，却未必能获得性能提升，因为可能需要更多的线程才会有效利用剩余的处理器。
如果CPU利用率很高，并且总会有可运行的线程在等待CPU，那么当增加更多的处理器时，程序的性能可能会得到提升。

## 总结

由于使用线程常常是为了充分利用多个处理器的计算能力，因此在并发程序性能的讨论中，通常更多地将侧重点放在吞吐量和可伸缩性上，而不是服务时间。Amdahl定律告诉我们，程序的可伸缩性取决于在所有代码中必须被串行执行的代码比例。因为Java程序中串行操作的主要来源是独占方式的资源锁，因此通常可以能票房破以下方式来提升可伸缩性：减少锁的持有时间，降低锁的粒度，以及采用非独占的锁或非阻塞锁来代替独占锁。

[^1]: **可伸缩性** 指的是：当增加计算资源时（例如CPU、内存、存储容量或I/O带宽），程序的吞吐量或者处理能力能相应地增加。

[^SpinWaiting]: **自旋等待**（Spin-Waiting）指通过循环不断地尝试获取锁，直到成功。